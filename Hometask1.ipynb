{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# АОЕЯ Hometask №1\n",
    "### Феоктистова Эмма\n",
    "### 3 курс ФиКЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __*Этап 1:*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала скачаем дату (возьмем отзывы о бирже фриланса FL.ru с сайта otzyvmarketing.ru):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html')\n",
    "    \n",
    "    half_matches = soup.find_all('div', class_='reviews_wrapper')\n",
    "    all_matches.extend(half_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://otzyvmarketing.ru/fl-ru/', 'https://otzyvmarketing.ru/fl-ru/?page=2', 'https://otzyvmarketing.ru/fl-ru/?page=3', 'https://otzyvmarketing.ru/fl-ru/?page=4']\n",
    "all_matches = []\n",
    "\n",
    "for url in urls:\n",
    "    get_comments(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сумме получилось 166 комментариев с различной оценкой пользователей (от 1й звезды до 5ти). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим полученные комментарии сразу на положительные и отрицательные (в качестве положительных будем считать отзывы с 4мя и 5ю звездами, отрицательных - 1-3 звезды):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "bad = []\n",
    "for i in all_matches:\n",
    "    try:\n",
    "        stars = i.find('div', {'class': 'stages_inner'})['style']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if stars == 'width: 100%;' or stars == 'width: 80%;':\n",
    "        good.append(i)\n",
    "    elif stars == 'width: 20%;' or stars == 'width: 40%;' or stars == 'width: 60%;':\n",
    "        bad.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "print(len(good))\n",
    "print(len(bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И вытащим из нашего html кода именно тексты отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_comments = []\n",
    "bad_comments = []\n",
    "for g in good:\n",
    "    try:\n",
    "        good_text = g.find('p', {'itemprop': \"description\"}).text\n",
    "        good_text = good_text.replace('\\xa0', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "        good_comments.append(good_text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for b in bad:\n",
    "    try:\n",
    "        bad_text = b.find('p', {'itemprop': \"description\"}).text\n",
    "        bad_text = bad_text.replace('\\xa0', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "        bad_comments.append(bad_text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_good = good_comments[0:10]\n",
    "testing_bad = bad_comments[0:10]\n",
    "good_comments = good_comments[10:]\n",
    "bad_comments = bad_comments[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __*Этап 2:*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем слова, предварительно приведя их в нижний регистр. Отсечем пунктуационные знаки и найдем начальную форму каждого слова. Все полученные данные также разделим на хорошие и плохие. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "good_prepared = []\n",
    "bad_prepared = []\n",
    "\n",
    "for i in good_comments:\n",
    "    good_words = nltk.word_tokenize(i.lower())\n",
    "    \n",
    "    for word in good_words:\n",
    "        if word.isalpha():\n",
    "            m = morph.parse(word)[0]\n",
    "            good_prepared.append(m.normal_form)\n",
    "\n",
    "for j in bad_comments:\n",
    "    bad_words = nltk.word_tokenize(j.lower())\n",
    "\n",
    "    for word in bad_words:\n",
    "        if word.isalpha():\n",
    "            m = morph.parse(word)[0]\n",
    "            bad_prepared.append(m.normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __*Этап 3:*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим множества слов, которые встречаются только в положительных комментариях и только в отрицательных.  Посчитаем их количество с помощью модуля Counter() и выведем самые частотные слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('доступный', 7),\n",
       " ('разработка', 7),\n",
       " ('копирайтинг', 6),\n",
       " ('уверить', 5),\n",
       " ('недостаток', 5),\n",
       " ('достоинство', 4),\n",
       " ('пришлый', 4),\n",
       " ('скидка', 4),\n",
       " ('профессиональный', 4),\n",
       " ('направление', 4),\n",
       " ('пополняться', 4),\n",
       " ('выступать', 4),\n",
       " ('счёт', 3),\n",
       " ('наличие', 3),\n",
       " ('решаться', 3),\n",
       " ('необходимость', 3),\n",
       " ('урок', 3),\n",
       " ('довольный', 3),\n",
       " ('тщательно', 3),\n",
       " ('доверять', 3),\n",
       " ('радовать', 3),\n",
       " ('достойный', 3),\n",
       " ('технический', 3),\n",
       " ('оперативно', 3),\n",
       " ('маркетинговый', 3),\n",
       " ('агентство', 3),\n",
       " ('анимация', 3),\n",
       " ('моделирование', 3),\n",
       " ('документ', 3),\n",
       " ('блог', 3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_counter = Counter()\n",
    "for word in good_prepared:\n",
    "    if word not in bad_prepared:\n",
    "        good_counter[word] += 1\n",
    "\n",
    "good_counter.most_common(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('переписка', 15),\n",
       " ('публикация', 14),\n",
       " ('вернуть', 14),\n",
       " ('сообщение', 13),\n",
       " ('пост', 13),\n",
       " ('никак', 12),\n",
       " ('ограничение', 11),\n",
       " ('ваш', 11),\n",
       " ('должный', 11),\n",
       " ('либо', 10),\n",
       " ('создавать', 10),\n",
       " ('фейковыя', 10),\n",
       " ('смотреть', 10),\n",
       " ('заблокировать', 10),\n",
       " ('конкурс', 10),\n",
       " ('уходить', 9),\n",
       " ('читать', 9),\n",
       " ('отправить', 9),\n",
       " ('нововведение', 9),\n",
       " ('письмо', 9),\n",
       " ('надо', 9),\n",
       " ('куча', 9),\n",
       " ('страница', 9),\n",
       " ('реальный', 9),\n",
       " ('опубликовать', 8),\n",
       " ('бс', 8),\n",
       " ('обращение', 7),\n",
       " ('просить', 7),\n",
       " ('ответить', 7),\n",
       " ('продолжать', 7)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_counter = Counter()\n",
    "for word in bad_prepared:\n",
    "    if word not in good_prepared:\n",
    "        bad_counter[word] += 1\n",
    "        \n",
    "bad_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __*Этап 4:*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функции, которые определяют положительный ли комментарий дан ей, либо отрицательный. Для этого аналогично подготавливаем текст проверяемого комментария, и проверяем, сколько слов из наших множеств встречаются в данном комментарии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def good_checking(comment):\n",
    "    is_good = 0\n",
    "    words = nltk.word_tokenize(comment.lower())\n",
    "    \n",
    "    to_check_good = []\n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            m = morph.parse(word)[0]\n",
    "            to_check_good.append(m.normal_form)\n",
    "    \n",
    "    for word in to_check_good:\n",
    "        if word in good_counter:\n",
    "            is_good += 1\n",
    "  \n",
    "    return is_good\n",
    "    \n",
    "def bad_checking(comment):\n",
    "    is_bad = 0\n",
    "    words = nltk.word_tokenize(comment.lower())\n",
    "    \n",
    "    to_check_bad = []\n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            m = morph.parse(word)[0]\n",
    "            to_check_bad.append(m.normal_form)\n",
    "            \n",
    "    for word in to_check_bad:\n",
    "        if word in bad_counter:\n",
    "            is_bad += 1\n",
    "\n",
    "    return is_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем наши тестовые комментарии, и проверим модель. также посчитаем accuracy нашей модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Комментарий положительный.\n",
      "Комментарий положительный.\n",
      "Комментарий положительный.\n",
      "\n",
      "Точность предсказания: 0.3000\n"
     ]
    }
   ],
   "source": [
    "results1 = []\n",
    "\n",
    "for i in testing_good:\n",
    "    g_number = good_checking(i)\n",
    "    b_number = bad_checking(i)\n",
    "    \n",
    "    if g_number > b_number:\n",
    "        results1.append(i)\n",
    "        print('Комментарий положительный.')\n",
    "    else:\n",
    "        results1.append('-')\n",
    "        \n",
    "\n",
    "a1 = accuracy_score(results1, testing_good)\n",
    "print('\\n' + 'Точность предсказания: ' + f'{a1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "Комментарий отрицательный.\n",
      "\n",
      "Точность предсказания: 0.9000\n"
     ]
    }
   ],
   "source": [
    "results2 = []\n",
    "\n",
    "for j in testing_bad:\n",
    "    g_number = good_checking(j)\n",
    "    b_number = bad_checking(j)\n",
    "    \n",
    "    if g_number < b_number:\n",
    "        results2.append(j)\n",
    "        print('Комментарий отрицательный.')\n",
    "    else:\n",
    "        results2.append('-')\n",
    "        \n",
    "\n",
    "a2 = accuracy_score(results2, testing_bad)\n",
    "print('\\n' + 'Точность предсказания: ' + f'{a2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, из-за небольшого кол-ва данных точность разнится (что можно пронаблюдать в случае с положительными комментариями). Также из-за наличия более менее нейтральных комментариев с 3-мя звездами множества пол./отр. слов не столь показательны и разняться между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Предложения и пожелания:*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Совет по оптимизации №1:**\n",
    "Например, собирать данные (отзывы/комментарии) с нескольких сайтов автоматически. Имеется в виду та ситуация, когда нужны отзывы о табуретках (пример), программа заходит на сайты с отзывами, забивает в поиске нужный товар и собирает данные. Тем самым выборка получится больше = множества корректнее = обученная модель точнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Совет по оптимизации №2:**\n",
    "Включить в параметры положительности/отрицательности отзыва не только слова, но и пунктуацию (типа: _табуретка огонь!!!!!_), а также смайлики, которые аналогично имеют эмоциональный окрас. В код в данном случае должны быть добавлены шаблоны с различными применениями пунктуации как отражения эмоций пользователя (еще пример - скобочки как показатель радости/грусти (\"_табуретка шатается((_\"). Также определители смайликов (например по id смайла определять, что он означает)).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
